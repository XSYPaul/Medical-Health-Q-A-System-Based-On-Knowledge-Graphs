{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/basic.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = './cleaning_data/cleaning_basic.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in file:\n",
    "    cleaning = {}\n",
    "    data = json.loads(line)\n",
    "    if data['page_num'] == -1:continue\n",
    "    cleaning['page_num'] = data['page_num']\n",
    "    cleaning['name'] = data['name']\n",
    "    \n",
    "    try:\n",
    "        cleaning['description'] = ''.join(data['description'].strip().split())\n",
    "    except:\n",
    "        cleaning['description'] = None\n",
    "        \n",
    "    try:\n",
    "        cleaning['assurance'] = data['assurance'][0]\n",
    "    except:\n",
    "        cleaning['assurance'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['sick_ratio'] = data['sick_ratio'][0]\n",
    "    except:\n",
    "        cleaning['sick_ratio'] =None\n",
    "    \n",
    "    try:\n",
    "        cleaning['weak_people'] = data['person'][0]\n",
    "    except:\n",
    "        cleaning['weak_people'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['infection'] = data['infection'][0]\n",
    "    except:\n",
    "        cleaning['infection'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['complication'] = data['complication'][0]\n",
    "    except:\n",
    "        cleaning['complication'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['department'] = data['department'][0]\n",
    "    except:\n",
    "        cleaning['department'] = None\n",
    "        \n",
    "    try:\n",
    "        cleaning['treatment'] = data['treatment'][0]\n",
    "    except:\n",
    "        cleaning['treatment'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['cure_period'] = data['period'][0]\n",
    "    except:\n",
    "        cleaning['cure_period'] = None\n",
    "        \n",
    "    try:\n",
    "        cleaning['cure_ratio'] = data['cure_ratio'][0]\n",
    "    except:\n",
    "        cleaning['cure_ratio'] = None\n",
    "        \n",
    "    try:\n",
    "        cleaning['drug'] = data['drug'][0].strip().split('\\n')[0:-3]\n",
    "    except:\n",
    "        cleaning['drug'] = None\n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for Cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/cause.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = './cleaning_data/cleaning_cause.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in file:\n",
    "    cleaning = {}\n",
    "    lst = []\n",
    "    data = json.loads(line)\n",
    "    if data['page_num'] == -1: continue\n",
    "    \n",
    "    cleaning['page_num'] = data['page_num']\n",
    "    cleaning['name'] = data['name']\n",
    "    \n",
    "    if data['cause']==None:\n",
    "        cleaning['cause'] = None\n",
    "    elif 0 < len(data['cause'][0]) < 13:\n",
    "        if len(data['cause'][0]) == 1:\n",
    "            cleaning['cause'] = data['cause'][0][0]\n",
    "        else:\n",
    "            for i in range(0,len(data['cause'][0]),2):\n",
    "                try:\n",
    "                    tmp = data['cause'][0][i]+data['cause'][0][i+1]\n",
    "                except:\n",
    "                    tmp = data['cause'][0][i]\n",
    "                lst.append(tmp)\n",
    "            cleaning['cause'] = lst\n",
    "    else:\n",
    "        cleaning['cause'] = ''.join(j for j in data['cause'][0])\n",
    " \n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "\n",
    "file_write.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for Complication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/complication.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = 'cleaning_complication.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in file:\n",
    "    cleaning = {}\n",
    "    data = json.loads(line)\n",
    "    if data['page_num'] == -1: continue\n",
    "    \n",
    "    cleaning['page_num'] = data['page_num']\n",
    "    cleaning['name'] = data['name']\n",
    "    \n",
    "    try:\n",
    "        cleaning['complication'] = data['complication'][0]\n",
    "    except:\n",
    "        cleaning['complication'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['description'] = data['description'].strip()\n",
    "    except:\n",
    "        cleaning['description'] = None\n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/diagnosis.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1、急性支气管炎和肺炎：由乙型流感杆菌，腺病毒，呼吸道合胞病毒，副流感病毒等引起的支气管炎，咳嗽较剧烈，常有痉咳，但剧烈咳嗽在起病数日内即出现，痉咳后无鸡鸣样回声，夜间不一定加重，急性期全身感染中毒症状如喘咳，气促较重，肺部常有固定的干湿Up音，白细胞计数正常或偏高，经适当治疗后，症状在短期内减轻或消失。2、支气管淋巴结结核：肿大的淋巴结压迫支气管，或侵蚀支气管壁，可引起痉挛性咳嗽，但无鸡鸣样回声。可根据结核病中毒症状，结核菌素试验，肺部X线改变等作出诊断。3、气管支气管异物：可突然发生阵发性痉咳，有异物吸入史，白细胞不增高，X线可见节段性肺不张，作支气管镜检查可发现异物。4、百日咳综合征：在普遍进行百日咳预防免疫的人群中，仍可有散发的“百日咳”病例出现，常分离出腺病毒，其他呼吸道病毒，肺炎支原体和副百日咳杆菌等，而无百日咳杆菌，其临床症状，肺部X线表现和血象所见，与典型百日咳有似之处，需靠病原学检查鉴别。据估计，约20%的病例系由上述病原所致，衣原体感染可有类似百日咳样咳嗽，但无鸡鸣样回声，副百日咳杆菌引起者症状轻，病程短。'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = json.loads(file[0])\n",
    "''.join(aa['judge'][0]) + ''.join(aa['diagnosis'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = './cleaning_data/cleaning_diagnosis.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in file:\n",
    "    cleaning = {}\n",
    "    lst = []\n",
    "    data = json.loads(line)\n",
    "    if data['page_num'] == -1: continue\n",
    "    \n",
    "    cleaning['page_num'] = data['page_num']+1\n",
    "    cleaning['name'] = data['name']\n",
    "    \n",
    "    try:\n",
    "        tmp = ''.join(data['diagnosis'][0]) + ''.join(data['judge'][0]) \n",
    "        cleaning['diagnosis'] = tmp\n",
    "    except:\n",
    "        cleaning['diagnosis'] = None\n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'drug.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = './cleaning_data/cleaning_drug.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in file:\n",
    "    cleaning = {}\n",
    "    lst = []\n",
    "    data = json.loads(line)\n",
    "    if data['page_num'] == -1: continue\n",
    "    \n",
    "    cleaning['page_num'] = data['page_num']\n",
    "    cleaning['name'] = data['name']\n",
    "    \n",
    "    if data['drug'] == None:\n",
    "        cleaning['drug'] = None\n",
    "    else:\n",
    "        tmp = data['drug'][0].strip().split(',')\n",
    "        for single in tmp:\n",
    "            tmp_str = single.strip().split()\n",
    "            if len(tmp_str) == 2:\n",
    "                tmp_str[1] = tmp_str[1][1:-1]\n",
    "            else:\n",
    "                tmp_str = tmp_str[:-1]\n",
    "            lst.append(tmp_str)\n",
    "        cleaning['drug'] = lst\n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/food.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = 'cleaning_food.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in file:\n",
    "    cleaning = {}\n",
    "    data = json.loads(line)\n",
    "    if data['page_num'] == -1: continue\n",
    "    \n",
    "    cleaning['page_num'] = data['page_num']\n",
    "    cleaning['name'] = data['name']\n",
    "    try:\n",
    "        cleaning['food_desc'] = ''.join(''.join(data['food'].strip().split('\\n\\r\\n\\t')).split('\\n'))\n",
    "    except:\n",
    "        cleaning['food_desc'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['good_food'] = data['good_food'][0]\n",
    "    except:\n",
    "        cleaning['good_food'] = None\n",
    "        \n",
    "    try:\n",
    "        cleaning['good_desc'] = [i.strip() for i in data['good'].strip().split('；')]\n",
    "    except:\n",
    "        cleaning['good_desc'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['bad_food'] = data['bad_food'][0]\n",
    "    except:\n",
    "        cleaning['bad_food'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['bad_desc'] = [i.strip() for i in data['bad'].strip().split('；')]\n",
    "    except:\n",
    "        cleaning['bad_desc'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['recommendation'] = data['recommendation'][0]\n",
    "    except:\n",
    "        cleaning['recommendation'] = None\n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/inspect.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = './cleaning_data/cleaning_inspect.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in file:\n",
    "    cleaning = {}\n",
    "    data = json.loads(line)\n",
    "    if data['page_num'] == -1: continue\n",
    "    \n",
    "    cleaning['page_num'] = data['page_num'] + 1\n",
    "    cleaning['name'] = data['name']\n",
    "    \n",
    "    try:\n",
    "        cleaning['item'] = data['item'][0]\n",
    "    except:\n",
    "        cleaning['item'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['desc'] = data['description'].strip()\n",
    "    except:\n",
    "        cleaning['desc'] = None\n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for nursing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/nursing.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = 'cleaning_nursing.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in file:\n",
    "    cleaning = {}\n",
    "    data = json.loads(line)\n",
    "    if data['page_num']==-1:continue\n",
    "    \n",
    "    cleaning['page_num'] = data['page_num'] + 1\n",
    "    cleaning['name'] = data['name']\n",
    "    try:\n",
    "        cleaning['desc'] = data['description']\n",
    "    except:\n",
    "        cleaning['desc'] = None\n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "    \n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for prevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/prevent.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = 'cleaning_prevent.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in file:\n",
    "    cleaning = {}\n",
    "    data = json.loads(line)\n",
    "    if data['page_num']==-1:continue\n",
    "        \n",
    "    cleaning['page_num'] = data['page_num']\n",
    "    cleaning['name'] = data['name']\n",
    "    \n",
    "    try:\n",
    "        cleaning['prevent'] = ''.join(i for i in data['prevention'])\n",
    "    except:\n",
    "        cleaning['prevent'] = None\n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "\n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for symptom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/symptom.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"_id\":{\"$oid\":\"5cea523c287942861f846057\"},\"page_num\":14,\"name\":\"肺曲菌病\",\"symptom\":[[\"咳出棕色痰栓\",\"嗜酸性粒细胞增多\",\"胸痛\"]],\"description\":\"临床上有四种类型。 一、支气管-肺炎型 曲菌菌丝在支气管粘膜上生长，但不侵入管壁。粘膜炎症轻微，有咳嗽、咳痰(痰可呈棕黄色)、低热等。如侵蚀肺组织，则可引起局限性的曲菌肉芽肿或肺炎、肺脓肿。 二、变态反应性曲菌病 对曲菌过敏者吸入大量孢子后，阻塞小支气管，引起短暂性肺不张，也可引起远端肺部出现反复游走性浸润。患者畏寒、发热、乏力、有刺激性咳嗽，咳棕黄色脓痰，有时带血。痰中有大量嗜酸粒细胞和曲菌丝。烟曲菌培养阳性。患者有显著哮喘，周围血嗜酸粒细胞增多。 三、曲菌球 曲菌寄生在肺部慢性疾病所伴有的空腔内(如肺囊肿、支气管扩张、肺结核空洞中)繁殖、储积，与纤维蛋白和粘膜细胞凝聚形成曲菌球，在X线下可见在原有的慢性空洞内有一团球影，随体位改变而在空腔内移动。曲菌球不侵犯组织，不引起病人全身症状，只 有刺激性咳嗽，有时可反复咯血。由于曲菌球与支气管多不连通，故痰不多，痰中亦常无曲菌发现。 四、继发性肺曲菌病 重病患者(如白血病、淋巴瘤)的终末阶段，以及使用广谱抗生素、免疫抑制药物或各种原因导致机体免疫力低下者 ，肺部所伴曲菌感染是局限性肉芽肿或广泛化脓性肺炎，伴脓肿形成。病灶呈急性凝固性坏死，伴坏死性血管炎、血栓和菌栓，甚至播及胸膜、脑膜、肝、脾等全身脏器，预后很差。\"}\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = './cleaning_data/cleaning_symptom.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in file:\n",
    "    cleaning = {}\n",
    "    data = json.loads(line)\n",
    "    if data['page_num'] == -1: continue\n",
    "    \n",
    "    cleaning['page_num'] = data['page_num']\n",
    "    cleaning['name'] = data['name']\n",
    "    \n",
    "    try:\n",
    "        cleaning['symptom'] = data['symptom'][0]\n",
    "    except:\n",
    "        cleaning['symptom'] = None\n",
    "        \n",
    "    try:\n",
    "        cleaning['desc'] = data['description'].split('/ ')[0]\n",
    "    except:\n",
    "        cleaning['desc'] = None\n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "\n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning for treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './raw_data/treatment.json'\n",
    "with open(path,'r') as f:\n",
    "    file = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照page_num排序\n",
    "lst = []\n",
    "for line in file:\n",
    "    data = json.loads(line)\n",
    "    if data['page_num'] == -1: continue\n",
    "    lst.append(data)\n",
    "lst.sort(key = operator.itemgetter('page_num'),reverse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = './cleaning_data/cleaning_treatment.json'\n",
    "file_write = open(path_write,'w')\n",
    "for line in lst:\n",
    "    cleaning = {}\n",
    "    \n",
    "    cleaning['page_num'] = line['page_num'] + 1\n",
    "    cleaning['name'] = line['name']\n",
    "    \n",
    "    try:\n",
    "        cleaning['department'] = line['department'][0]\n",
    "    except:\n",
    "        cleaning['department'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['approach'] = line['approach'][0]\n",
    "    except:\n",
    "        cleaning['approach'] = None\n",
    "    \n",
    "    try :\n",
    "        cleaning['cure_ratio'] = line['sick_ration'][0]\n",
    "    except:\n",
    "        cleaning['cure_ratio'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['period'] = line['period'][0]\n",
    "    except:\n",
    "        cleaning['period'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['drug'] = line['drug'][0]\n",
    "    except:\n",
    "        cleaning['drug'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['charge'] = line['charge'][0].strip()\n",
    "    except:\n",
    "        cleaning['charge'] = None\n",
    "    \n",
    "    try:\n",
    "        cleaning['desc'] = line['description'].strip()\n",
    "    except:\n",
    "        cleaning['desc'] = None\n",
    "    \n",
    "    item = json.dumps(cleaning,ensure_ascii=False)\n",
    "    file_write.write(item)\n",
    "    file_write.write('\\n')\n",
    "\n",
    "file_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
